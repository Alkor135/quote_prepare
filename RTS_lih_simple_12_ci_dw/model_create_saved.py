import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import random
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
import os
from data_read import data_load, balance_classes
import shutil
import sys
sys.dont_write_bytecode = True

# === –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ ===
def set_seed(seed):
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# === –°–û–ó–î–ê–ù–ò–ï –ù–ï–ô–†–û–°–ï–¢–ò (LSTM) ===
class CandleLSTM(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, day_vocab_size, day_embedding_dim):
        super(CandleLSTM, self).__init__()
        self.embedding_candle = nn.Embedding(vocab_size, embedding_dim)  # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–≤–µ—á–Ω—ã—Ö –∫–æ–¥–æ–≤
        self.embedding_day = nn.Embedding(day_vocab_size, day_embedding_dim)  # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏
        self.lstm = nn.LSTM(embedding_dim + day_embedding_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x_candle, x_day):
        x_candle = self.embedding_candle(x_candle)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–≤–µ—á–Ω—ã–µ –∫–æ–¥—ã –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        x_day = self.embedding_day(x_day)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–Ω–∏ –Ω–µ–¥–µ–ª–∏ –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        x = torch.cat((x_candle, x_day), dim=-1)  # –û–±—ä–µ–¥–∏–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–≤–µ—á–µ–π –∏ –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏
        x, _ = self.lstm(x)
        x = self.fc(x[:, -1, :])
        return self.sigmoid(x)

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
class CandlestickDataset(Dataset):
    def __init__(self, X_candle, X_day, y):
        self.X_candle = torch.tensor(X_candle, dtype=torch.long)
        self.X_day = torch.tensor(X_day, dtype=torch.long)
        self.y = torch.tensor(y, dtype=torch.float32)

    def __len__(self):
        return len(self.X_candle)

    def __getitem__(self, idx):
        return self.X_candle[idx], self.X_day[idx], self.y[idx]

def seed_worker(worker_id):
    np.random.seed(42 + worker_id)
    random.seed(42 + worker_id)

# === –§—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ P/L (–ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–º—É –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é) ===
def calculate_pnl(y_preds, open_prices, close_prices):
    pnl = 0
    for i in range(len(y_preds)):
        if y_preds[i] > 0.5:  # –ü–æ–∫—É–ø–∫–∞ (LONG)
            pnl += close_prices[i] - open_prices[i]
        else:  # –ü—Ä–æ–¥–∞–∂–∞ (SHORT)
            pnl += open_prices[i] - close_prices[i]
    return pnl  # –ò—Ç–æ–≥–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å

# === 1. –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø ===
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –ø–∞–ø–∫—É, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —Ñ–∞–π–ª —Å–∫—Ä–∏–ø—Ç–∞
script_dir = Path(__file__).parent
os.chdir(script_dir)

# === 2. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø –ò –í–ê–õ–ò–î–ê–¶–ò–ò ===
db_path = Path(r'C:\Users\Alkor\gd\data_quote_db\RTS_futures_options_day_2014.db')
df = data_load(db_path, '2014-01-01', '2024-01-01')

for counter in range(1, 101):
    # –£–¥–∞–ª—è–µ–º –ø–∞–ø–∫—É __pycache__ (–µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞)
    shutil.rmtree('__pycache__', ignore_errors=True)

    set_seed(counter)  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π seed

    df_fut = df.copy()

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X_candle = df_fut[[f'CI_{i}' for i in range(1, 21)]].values
    X_day = df_fut[[f'DAY_W_{i}' for i in range(0, 20)]].values
    y = df_fut['DIRECTION'].values
    X_candle, X_day, y = np.array(X_candle), np.array(X_day), np.array(y)

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
    split = int(0.85 * len(X_candle))
    X_candle_train, X_candle_test = X_candle[:split], X_candle[split:]
    X_day_train, X_day_test = X_day[:split], X_day[split:]
    y_train, y_test = y[:split], y[split:]

    # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
    X_candle_train, X_day_train, y_train = balance_classes(X_candle_train, X_day_train, y_train)

    # === 5. –°–û–ó–î–ê–ù–ò–ï DATASET –∏ DATALOADER ===
    X_candle_test = np.array(X_candle_test, dtype=np.int64)  # –ü—Ä–∏–≤–µ—Å—Ç–∏ –∫ —á–∏—Å–ª–æ–≤–æ–º—É —Ç–∏–ø—É
    X_day_test = np.array(X_day_test, dtype=np.int64)  # –ü—Ä–∏–≤–µ—Å—Ç–∏ –∫ —á–∏—Å–ª–æ–≤–æ–º—É —Ç–∏–ø—É
    y_test = np.array(y_test, dtype=np.int64)  # –ü—Ä–∏–≤–µ—Å—Ç–∏ –∫ —á–∏—Å–ª–æ–≤–æ–º—É —Ç–∏–ø—É

    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader
    train_dataset = CandlestickDataset(X_candle_train, X_day_train, y_train)
    test_dataset = CandlestickDataset(X_candle_test, X_day_test, y_test)

    train_loader = DataLoader(
        train_dataset, batch_size=32, shuffle=True, worker_init_fn=seed_worker
        )
    test_loader = DataLoader(
        test_dataset, batch_size=32, shuffle=False, worker_init_fn=seed_worker
        )

    # === 6. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –° –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ï–ô –ü–û P/L ===
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    vocab_size = 27  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–¥–æ–≤ —Å–≤–µ—á–µ–π
    embedding_dim = 16
    day_vocab_size = 7  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏ (0-6)
    day_embedding_dim = 4
    hidden_dim = 64
    output_dim = 1

    model = CandleLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, day_vocab_size, day_embedding_dim).to(device)
    criterion = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    best_pnl = float('-inf')  # –õ—É—á—à–∞—è –ø—Ä–∏–±—ã–ª—å (–∏–∑–Ω–∞—á–∞–ª—å–Ω–æ -‚àû)
    epoch_best_pnl = 0
    model_path = Path(fr"model\best_model_{counter}.pth")
    early_stop_epochs = 200
    epochs_no_improve = 0

    epochs = 2000
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for X_candle_batch, X_day_batch, y_batch in train_loader:
            X_candle_batch, X_day_batch, y_batch = (
                X_candle_batch.to(device),
                X_day_batch.to(device),
                y_batch.to(device),
            )

            optimizer.zero_grad()
            y_pred = model(X_candle_batch, X_day_batch).squeeze()
            loss = criterion(y_pred, y_batch)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ ===
        model.eval()
        y_preds = []
        
        with torch.no_grad():
            for X_candle_batch, X_day_batch, y_batch in test_loader:
                X_candle_batch, X_day_batch = X_candle_batch.to(device), X_day_batch.to(device)
                y_pred = model(X_candle_batch, X_day_batch).squeeze().cpu().numpy()
                y_preds.extend(y_pred)

        # === –†–∞—Å—á–µ—Ç P/L ===
        test_open_prices = df_fut['OPEN'].iloc[split:].values
        test_close_prices = df_fut['CLOSE'].iloc[split:].values
        pnl = calculate_pnl(y_preds, test_open_prices, test_close_prices)

        print(
            f"Epoch {epoch + 1}/{epochs}, "
            f"Loss: {total_loss / len(train_loader):.5f}, "
            f"P/L: {pnl:.2f}, "
            f"Best P/L: {best_pnl:.2f}, "
            f"Epoch best P/L: {epoch_best_pnl}, "
            f"seed: {counter}"
        )

        # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ P/L ===
        if pnl > best_pnl:
            best_pnl = pnl
            epochs_no_improve = 0
            epoch_best_pnl = epoch + 1
            torch.save(model.state_dict(), model_path)
            print(f"‚úÖ Model saved with P/L: {best_pnl:.2f}")
        else:
            epochs_no_improve += 1

        # === –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ ===
        if epochs_no_improve >= early_stop_epochs:
            print(f"üõë Early stopping at epoch {epoch + 1}")
            break

    # === 7. –ó–ê–ì–†–£–ó–ö–ê –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò –ò –§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ ===
    print("\nüîπ Loading best model for final evaluation...")
    model.load_state_dict(torch.load(model_path))
    model.eval()

    y_preds_final = []

    with torch.no_grad():
        for X_candle_batch, X_day_batch, y_batch in test_loader:
            X_candle_batch, X_day_batch = X_candle_batch.to(device), X_day_batch.to(device)
            y_pred = model(X_candle_batch, X_day_batch).squeeze().cpu().numpy()
            y_preds_final.extend(y_pred)

    final_pnl = calculate_pnl(y_preds_final, test_open_prices, test_close_prices)
    print(f"üèÜ Final Test P/L: {final_pnl:.2f}")
