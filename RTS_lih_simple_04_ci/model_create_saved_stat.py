import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import random
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
import os
from data_read import data_load, balance_classes
import shutil
import sys
sys.dont_write_bytecode = True

# === Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• ĞĞ•Ğ™Ğ ĞĞ¡Ğ•Ğ¢Ğ˜ (LSTM) ===
class CandleLSTM(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):
        super(CandleLSTM, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.embedding(x)
        x, _ = self.lstm(x)
        x = self.fc(x[:, -1, :])
        return self.sigmoid(x)

class CandlestickDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.long)
        self.y = torch.tensor(y, dtype=torch.float32)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def seed_worker(worker_id):
    np.random.seed(42 + worker_id)
    random.seed(42 + worker_id)


# === Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ seed Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ===
def set_seed(seed):
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


# === Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ€Ğ°ÑÑ‡ĞµÑ‚Ğ° P/L (Ğ¿Ğ¾ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ) ===
def calculate_pnl(y_preds, open_prices, close_prices):
    pnl = 0
    for i in range(len(y_preds)):
        if y_preds[i] > 0.5:  # ĞŸĞ¾ĞºÑƒĞ¿ĞºĞ° (LONG)
            pnl += close_prices[i] - open_prices[i]
        else:  # ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ° (SHORT)
            pnl += open_prices[i] - close_prices[i]
    return pnl  # Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ

# === 1. ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ¯ ===
# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ñ€Ğ°Ğ±Ğ¾Ñ‡ĞµĞ¹ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ² Ğ¿Ğ°Ğ¿ĞºÑƒ, Ğ³Ğ´Ğµ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ñ„Ğ°Ğ¹Ğ» ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ°
script_dir = Path(__file__).parent
os.chdir(script_dir)

# === 2. Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ”ĞĞĞĞ«Ğ¥ Ğ”Ğ›Ğ¯ ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ¯ Ğ˜ Ğ’ĞĞ›Ğ˜Ğ”ĞĞ¦Ğ˜Ğ˜ ===
db_path = Path(r'C:\Users\Alkor\gd\data_quote_db\RTS_day_2014.db')
df = data_load(db_path, '2014-01-01', '2024-01-01')

for counter in range(1, 101):
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¿Ğ°Ğ¿ĞºÑƒ __pycache__ (ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ° Ğ±Ñ‹Ğ»Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°)
    shutil.rmtree('__pycache__', ignore_errors=True)

    set_seed(counter)  # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ğ¹ seed

    df_fut = df.copy()

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ñ‚Ğ° ÑĞµÑ‚Ğ¾Ğ²
    X = df_fut[[f'CI_{i}' for i in range(1, 21)]].values
    y = df_fut['DIRECTION']
    X, y = np.array(X), np.array(y)

    # Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ° train/test
    split = int(0.85 * len(X))
    X_train, y_train = X[:split], y[:split]
    X_test, y_test = X[split:], y[split:]

    # === 4. Ğ‘Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° ĞºĞ»Ğ°ÑÑĞ¾Ğ² === 
    X_train, y_train = balance_classes(X_train, y_train)

    # === 5. Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• DATASET Ğ¸ DATALOADER ===
    X_test = np.array(X_test, dtype=np.int64)  # ĞŸÑ€Ğ¸Ğ²ĞµÑÑ‚Ğ¸ Ğº Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ñ‚Ğ¸Ğ¿Ñƒ
    y_test = np.array(y_test, dtype=np.int64)  # ĞŸÑ€Ğ¸Ğ²ĞµÑÑ‚Ğ¸ Ğº Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ñ‚Ğ¸Ğ¿Ñƒ

    train_dataset = CandlestickDataset(X_train, y_train)
    test_dataset = CandlestickDataset(X_test, y_test)

    train_loader = DataLoader(
        train_dataset, batch_size=32, shuffle=True, worker_init_fn=seed_worker
        )
    test_loader = DataLoader(
        test_dataset, batch_size=32, shuffle=False, worker_init_fn=seed_worker
        )

    # === 6. ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ• ĞœĞĞ”Ğ•Ğ›Ğ˜ Ğ¡ ĞĞŸĞ¢Ğ˜ĞœĞ˜Ğ—ĞĞ¦Ğ˜Ğ•Ğ™ ĞŸĞ P/L ===
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model = CandleLSTM(vocab_size=27, embedding_dim=8, hidden_dim=32, output_dim=1).to(device)
    criterion = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    best_pnl = float('-inf')  # Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ (Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾ -âˆ)
    epoch_best_pnl = 0
    model_path = Path(fr"model\best_model_{counter}.pth")
    early_stop_epochs = 200
    epochs_no_improve = 0

    epochs = 2000
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            optimizer.zero_grad()
            y_pred = model(X_batch).squeeze()
            loss = criterion(y_pred, y_batch)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        # === ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğµ Ğ¿Ğ¾ÑĞ»Ğµ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ ÑĞ¿Ğ¾Ñ…Ğ¸ ===
        model.eval()
        y_preds = []
        
        with torch.no_grad():
            for X_batch, _ in test_loader:
                X_batch = X_batch.to(device)
                y_pred = model(X_batch).squeeze().cpu().numpy()
                y_preds.extend(y_pred)

        # === Ğ Ğ°ÑÑ‡ĞµÑ‚ P/L ===
        test_open_prices = df_fut['OPEN'].iloc[split:].values
        test_close_prices = df_fut['CLOSE'].iloc[split:].values
        pnl = calculate_pnl(y_preds, test_open_prices, test_close_prices)

        print(
            f"Epoch {epoch + 1}/{epochs}, "
            f"Loss: {total_loss / len(train_loader):.5f}, "
            f"P/L: {pnl:.2f}, "
            f"Best P/L: {best_pnl:.2f}, "
            f"Epoch best P/L: {epoch_best_pnl}, "
            f"seed: {counter}"
        )

        # === Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ P/L ===
        if pnl > best_pnl:
            best_pnl = pnl
            epochs_no_improve = 0
            epoch_best_pnl = epoch + 1
            torch.save(model.state_dict(), model_path)
            print(f"âœ… Model saved with P/L: {best_pnl:.2f}")
        else:
            epochs_no_improve += 1

        # === Ğ Ğ°Ğ½Ğ½ÑÑ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° ===
        if epochs_no_improve >= early_stop_epochs:
            print(f"ğŸ›‘ Early stopping at epoch {epoch + 1}")
            break

    # === 7. Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ›Ğ£Ğ§Ğ¨Ğ•Ğ™ ĞœĞĞ”Ğ•Ğ›Ğ˜ Ğ˜ Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞ«Ğ™ Ğ¢Ğ•Ğ¡Ğ¢ ===
    print("\nğŸ”¹ Loading best model for final evaluation...")
    model.load_state_dict(torch.load(model_path))
    model.eval()

    y_preds_final = []
    with torch.no_grad():
        for X_batch, _ in test_loader:
            X_batch = X_batch.to(device)
            y_pred = model(X_batch).squeeze().cpu().numpy()
            y_preds_final.extend(y_pred)

    final_pnl = calculate_pnl(y_preds_final, test_open_prices, test_close_prices)
    print(f"ğŸ† Final Test P/L: {final_pnl:.2f}")
