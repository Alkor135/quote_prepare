"""
–î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤ —Ñ–∞–π–ª—ã. –õ–∏—Ö–æ–≤–∏–¥–æ–≤. –ë–∏–Ω–∞—Ä–∫–∞
"""

import sqlite3
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import random
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt

for counter in range(1, 101):
    # === 1. –§–ò–ö–°–ê–¶–ò–Ø –°–õ–£–ß–ê–ô–ù–´–• –ß–ò–°–ï–õ –î–õ–Ø –î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–û–°–¢–ò ===
    def set_seed(seed=42):
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

    set_seed(counter)  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π seed

    # === 2. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===
    db_path = Path(r'C:\Users\Alkor\gd\data_quote_db\RTS_futures_day.db')

    with sqlite3.connect(db_path) as conn:
        df_fut = pd.read_sql_query(
            "SELECT TRADEDATE, OPEN, LOW, HIGH, CLOSE, VOLUME FROM Day",
            conn
        )

    # # –§–∏–∫—Å–∞—Ü–∏—è –ø–æ—Ä—è–¥–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ)
    # df_fut = df_fut.sample(frac=1, random_state=42).reset_index(drop=True)

    # === 3. –§–£–ù–ö–¶–ò–Ø –ö–û–î–ò–†–û–í–ê–ù–ò–Ø –°–í–ï–ß–ï–ô (–õ–ò–•–û–í–ò–î–û–í) ===
    def encode_candle(row):
        open_, low, high, close = row['OPEN'], row['LOW'], row['HIGH'], row['CLOSE']

        direction = 1 if close > open_ else (0 if close < open_ else 2)
        upper_shadow = high - max(open_, close)
        lower_shadow = min(open_, close) - low
        body = abs(close - open_)

        def classify_shadow(shadow, body):
            return 0 if shadow < 0.1 * body else (1 if shadow < 0.5 * body else 2)

        return f"{direction}{classify_shadow(upper_shadow, body)}{classify_shadow(lower_shadow, body)}"


    df_fut['CANDLE_CODE'] = df_fut.apply(encode_candle, axis=1)

    # === 4. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ===
    unique_codes = sorted(df_fut['CANDLE_CODE'].unique())
    code_to_int = {code: i for i, code in enumerate(unique_codes)}
    df_fut['CANDLE_INT'] = df_fut['CANDLE_CODE'].map(code_to_int)

    window_size = 20
    predict_offset = 1

    X, y = [], []
    for i in range(len(df_fut) - window_size - predict_offset):
        X.append(df_fut['CANDLE_INT'].iloc[i:i + window_size].values)
        y.append(
            1 if df_fut['CLOSE'].iloc[i + window_size + predict_offset] >
                 df_fut['CLOSE'].iloc[i + window_size] else 0
        )

    X, y = np.array(X), np.array(y)

    split = int(0.8 * len(X))
    X_train, y_train = X[:split], y[:split]
    X_test, y_test = X[split:], y[split:]


    class CandlestickDataset(Dataset):
        def __init__(self, X, y):
            self.X = torch.tensor(X, dtype=torch.long)
            self.y = torch.tensor(y, dtype=torch.float32)

        def __len__(self):
            return len(self.X)

        def __getitem__(self, idx):
            return self.X[idx], self.y[idx]


    def seed_worker(worker_id):
        np.random.seed(42 + worker_id)
        random.seed(42 + worker_id)


    train_dataset = CandlestickDataset(X_train, y_train)
    test_dataset = CandlestickDataset(X_test, y_test)
    # print(X_train)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ –Ω–µ –∏—Å–ø–æ—Ä—Ç–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –§–∏—á–∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã.

    train_loader = DataLoader(
        train_dataset, batch_size=32, shuffle=True, worker_init_fn=seed_worker
    )
    test_loader = DataLoader(
        test_dataset, batch_size=32, shuffle=False, worker_init_fn=seed_worker
    )


    # === 5. –°–û–ó–î–ê–ù–ò–ï –ù–ï–ô–†–û–°–ï–¢–ò (LSTM) ===
    class CandleLSTM(nn.Module):
        def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):
            super(CandleLSTM, self).__init__()
            self.embedding = nn.Embedding(vocab_size, embedding_dim)
            self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)
            self.fc = nn.Linear(hidden_dim, output_dim)
            self.sigmoid = nn.Sigmoid()

        def forward(self, x):
            x = self.embedding(x)
            x, _ = self.lstm(x)
            x = self.fc(x[:, -1, :])
            return self.sigmoid(x)


    # === 6. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –° –°–û–•–†–ê–ù–ï–ù–ò–ï–ú –õ–£–ß–®–ï–ô ===
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model = CandleLSTM(
        vocab_size=len(unique_codes), embedding_dim=8, hidden_dim=32, output_dim=1
    ).to(device)
    criterion = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    best_accuracy = 0
    epoch_best_accuracy = 0
    model_path = Path(r"best_model_graph_RTS.pth")
    early_stop_epochs = 200
    epochs_no_improve = 0

    epochs = 2000
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)

            optimizer.zero_grad()
            y_pred = model(X_batch).squeeze()
            loss = criterion(y_pred, y_batch)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ ===
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for X_batch, y_batch in test_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                y_pred = model(X_batch).squeeze().round()
                correct += (y_pred == y_batch).sum().item()
                total += y_batch.size(0)

        accuracy = correct / total
        print(
            f"Epoch {epoch + 1}/{epochs}, "
            f"Loss: {total_loss / len(train_loader):.4f}, "
            f"Test Accuracy: {accuracy:.2%}, "
            f"Best accuracy: {best_accuracy:.2%}, "
            f"Epoch best accuracy: {epoch_best_accuracy}, "
            f"seed: {counter}"
        )

        # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ ===
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            epochs_no_improve = 0
            epoch_best_accuracy = epoch + 1
            torch.save(model.state_dict(), model_path)
            print(f"‚úÖ Model saved with accuracy: {best_accuracy:.2%}")
        else:
            epochs_no_improve += 1

        # === –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ ===
        if epochs_no_improve >= early_stop_epochs:
            print(f"üõë Early stopping at epoch {epoch + 1}")
            break

    # === 7. –ó–ê–ì–†–£–ó–ö–ê –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò –ò –¢–ï–°–¢ ===
    print("\nüîπ Loading best model for final evaluation...")
    model.load_state_dict(torch.load(model_path))
    model.eval()

    correct = 0
    total = 0
    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            y_pred = model(X_batch).squeeze().round()
            correct += (y_pred == y_batch).sum().item()
            total += y_batch.size(0)

    final_accuracy = correct / total
    print(f"üèÜ Final Test Accuracy: {final_accuracy:.2%}")

    # --------------------------------------------------------------------------------------------
    # === 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===
    # db_path = Path(r'C:\Users\Alkor\gd\data_quote_db\RTS_futures_options_day.db')

    # with sqlite3.connect(db_path) as conn:
    #     df_fut = pd.read_sql_query(
    #         "SELECT TRADEDATE, OPEN, LOW, HIGH, CLOSE, VOLUME FROM Futures",
    #         conn
    #     )
    db_path = Path(r'C:\Users\Alkor\gd\data_quote_db\RTS_futures_day.db')

    with sqlite3.connect(db_path) as conn:
        df_fut = pd.read_sql_query(
            "SELECT TRADEDATE, OPEN, LOW, HIGH, CLOSE, VOLUME FROM Day",
            conn
        )


    # === 2. –§–£–ù–ö–¶–ò–Ø –ö–û–î–ò–†–û–í–ê–ù–ò–Ø –°–í–ï–ß–ï–ô (–õ–ò–•–û–í–ò–î–û–í) ===
    def encode_candle(row):
        open_, low, high, close = row['OPEN'], row['LOW'], row['HIGH'], row['CLOSE']

        direction = 1 if close > open_ else (0 if close < open_ else 2)
        upper_shadow = high - max(open_, close)
        lower_shadow = min(open_, close) - low
        body = abs(close - open_)

        def classify_shadow(shadow, body):
            return 0 if shadow < 0.1 * body else (1 if shadow < 0.5 * body else 2)

        return f"{direction}{classify_shadow(upper_shadow, body)}{classify_shadow(lower_shadow, body)}"


    df_fut['CANDLE_CODE'] = df_fut.apply(encode_candle, axis=1)

    # === 3. –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –ö–û–î–û–í –í –ß–ò–°–õ–ê ===
    unique_codes = sorted(df_fut['CANDLE_CODE'].unique())
    code_to_int = {code: i for i, code in enumerate(unique_codes)}
    df_fut['CANDLE_INT'] = df_fut['CANDLE_CODE'].map(code_to_int)

    window_size = 20


    # === 4. –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ú–û–î–ï–õ–ò (–î–û–õ–ñ–ù–ê –°–û–í–ü–ê–î–ê–¢–¨ –° –û–ë–£–ß–ï–ù–ù–û–ô) ===
    class CandleLSTM(nn.Module):
        def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):
            super(CandleLSTM, self).__init__()
            self.embedding = nn.Embedding(vocab_size, embedding_dim)
            self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)
            self.fc = nn.Linear(hidden_dim, output_dim)
            self.sigmoid = nn.Sigmoid()

        def forward(self, x):
            x = self.embedding(x)
            x, _ = self.lstm(x)
            x = self.fc(x[:, -1, :])
            return self.sigmoid(x)


    # === 5. –ó–ê–ì–†–£–ó–ö–ê –û–ë–£–ß–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò ===
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model_path = Path(r"best_model_graph_RTS.pth")
    model = CandleLSTM(
        vocab_size=len(unique_codes), embedding_dim=8, hidden_dim=32, output_dim=1
    ).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    # === 6. –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–ï ===
    predictions = []
    with torch.no_grad():
        for i in range(len(df_fut) - window_size):
            sequence = torch.tensor(
                df_fut['CANDLE_INT'].iloc[i:i + window_size].values, dtype=torch.long
            ).unsqueeze(0).to(device)
            pred = model(sequence).item()
            predictions.append(1 if pred > 0.5 else 0)

    # –ó–∞–ø–æ–ª–Ω—è–µ–º –∫–æ–ª–æ–Ω–∫—É PREDICTION (–ø–µ—Ä–≤—ã–µ window_size –∑–Ω–∞—á–µ–Ω–∏–π - NaN)
    df_fut['PREDICTION'] = [None] * window_size + predictions

    # === 7. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
    predictions_file = Path(r"predictions_graph_RTS.csv")
    df_fut.to_csv(predictions_file, index=False)
    print(f"‚úÖ –ü—Ä–æ–≥–Ω–æ–∑—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ '{predictions_file}'")

    # -------------------------------------------------------------------------------------
    # === 1. –ó–ê–ì–†–£–ó–ö–ê –§–ê–ô–õ–ê –ò –û–¢–ë–û–† –ü–û–°–õ–ï–î–ù–ò–• 20% ===
    df = pd.read_csv(predictions_file)

    split = int(len(df) * 0.8)  # 80% - –æ–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞, 20% - —Ç–µ—Å—Ç–æ–≤–∞—è
    df = df.iloc[split:].copy()  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20%

    # === 2. –°–ú–ï–©–ï–ù–ò–ï –ü–†–û–ì–ù–û–ó–ê –ù–ê –û–î–ò–ù –ë–ê–† –í–ü–ï–†–Å–î ===
    df["PREDICTION_SHIFTED"] = df["PREDICTION"].shift(1)  # –°–º–µ—â–∞–µ–º –≤–≤–µ—Ä—Ö


    # df

    # === 3. –†–ê–°–ß–Å–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ü–†–û–ì–ù–û–ó–ê ===
    def calculate_result(row):
        if pd.isna(row["PREDICTION_SHIFTED"]):  # –ï—Å–ª–∏ NaN –ø–æ—Å–ª–µ —Å–¥–≤–∏–≥–∞
            return 0  # –ú–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –∏–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å 0

        true_direction = 1 if row["CLOSE"] > row["OPEN"] else 0
        predicted_direction = row["PREDICTION_SHIFTED"]

        difference = abs(row["CLOSE"] - row["OPEN"])
        return difference if true_direction == predicted_direction else -difference


    df["RESULT"] = df.apply(calculate_result, axis=1)

    # === 4. –ü–û–°–¢–†–û–ï–ù–ò–ï –ö–£–ú–£–õ–Ø–¢–ò–í–ù–û–ì–û –ì–†–ê–§–ò–ö–ê ===
    df["CUMULATIVE_RESULT"] = df["RESULT"].cumsum()

    plt.figure(figsize=(12, 6))
    plt.plot(df["TRADEDATE"], df["CUMULATIVE_RESULT"], label="Cumulative Result", color="b")
    plt.xlabel("Date")
    plt.ylabel("Cumulative Result")
    plt.title(f"Cumulative Sum of Prediction Accuracy. set_seed={counter}, "
              f"Best accuracy: {best_accuracy:.2%}, "
              f"Epoch best accuracy: {epoch_best_accuracy}")
    plt.legend()
    plt.grid()

    # plt.xticks(rotation=45)
    plt.xticks(df["TRADEDATE"][::10], rotation=90)
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –≤ —Ñ–∞–π–ª
    img_path = Path(fr"img_RTS/seed_{counter}_RTS.png")
    plt.savefig(img_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: '{img_path}' \n")
    # plt.show()
