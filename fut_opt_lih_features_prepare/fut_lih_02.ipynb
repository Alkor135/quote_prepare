{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Å–≤–µ—á–µ–π –ø–æ –º–µ—Ç–æ–¥—É –õ–∏—Ö–æ–≤–∏–¥–æ–≤–∞, –ø—Ä–æ–≥–Ω–æ–∑ Up –∏–ª–∏ Down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–¥–∞ —Å–≤–µ—á–∏ –õ–∏—Ö–æ–≤–∏–¥–æ–≤–∞.  \n",
    "–ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è Up –∏–ª–∏ Down.  \n",
    "–û—Å–Ω–æ–≤–Ω–æ–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä seed. –ü–æ–¥–±–∏—Ä–∞–µ—Ç—Å—è –ø–æ –≥—Ä–∞—Ñ–∏–∫–∞–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # –ù–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "# import sqlite3\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# # === 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===\n",
    "# db_path = Path(r'C:\\Users\\Alkor\\gd\\data_quote_db\\RTS_futures_options_day.db')\n",
    "\n",
    "# with sqlite3.connect(db_path) as conn:\n",
    "#     df_fut = pd.read_sql_query(\n",
    "#         \"SELECT TRADEDATE, OPEN, LOW, HIGH, CLOSE, VOLUME FROM Futures\",\n",
    "#         conn\n",
    "#     )\n",
    "\n",
    "# # === 2. –§–£–ù–ö–¶–ò–Ø –ö–û–î–ò–†–û–í–ê–ù–ò–Ø –°–í–ï–ß–ï–ô (–õ–ò–•–û–í–ò–î–û–í) ===\n",
    "# def encode_candle(row):\n",
    "#     open_, low, high, close = row['OPEN'], row['LOW'], row['HIGH'], row['CLOSE']\n",
    "\n",
    "#     if close > open_:\n",
    "#         direction = 1  \n",
    "#     elif close < open_:\n",
    "#         direction = 0  \n",
    "#     else:\n",
    "#         direction = 2  \n",
    "\n",
    "#     upper_shadow = high - max(open_, close)\n",
    "#     lower_shadow = min(open_, close) - low\n",
    "#     body = abs(close - open_)\n",
    "\n",
    "#     def classify_shadow(shadow, body):\n",
    "#         if shadow < 0.1 * body:\n",
    "#             return 0  \n",
    "#         elif shadow < 0.5 * body:\n",
    "#             return 1  \n",
    "#         else:\n",
    "#             return 2  \n",
    "\n",
    "#     upper_code = classify_shadow(upper_shadow, body)\n",
    "#     lower_code = classify_shadow(lower_shadow, body)\n",
    "\n",
    "#     return f\"{direction}{upper_code}{lower_code}\"\n",
    "\n",
    "# df_fut['CANDLE_CODE'] = df_fut.apply(encode_candle, axis=1)\n",
    "\n",
    "# # === 3. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ===\n",
    "# unique_codes = sorted(df_fut['CANDLE_CODE'].unique())\n",
    "# code_to_int = {code: i for i, code in enumerate(unique_codes)}\n",
    "# df_fut['CANDLE_INT'] = df_fut['CANDLE_CODE'].map(code_to_int)\n",
    "\n",
    "# window_size = 20  \n",
    "# predict_offset = 1  \n",
    "\n",
    "# X, y = [], []\n",
    "# for i in range(len(df_fut) - window_size - predict_offset):\n",
    "#     # Add features\n",
    "#     X.append(df_fut['CANDLE_INT'].iloc[i:i+window_size].values)\n",
    "#     # Add target\n",
    "#     y.append(\n",
    "#         1 if df_fut['CLOSE'].iloc[i+window_size+predict_offset] > \n",
    "#         df_fut['CLOSE'].iloc[i+window_size] else 0\n",
    "#         )\n",
    "\n",
    "# X, y = np.array(X), np.array(y)\n",
    "\n",
    "# split = int(0.8 * len(X))\n",
    "# X_train, y_train = X[:split], y[:split]\n",
    "# X_test, y_test = X[split:], y[split:]\n",
    "\n",
    "# class CandlestickDataset(Dataset):\n",
    "#     def __init__(self, X, y):\n",
    "#         self.X = torch.tensor(X, dtype=torch.long)\n",
    "#         self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.X)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.X[idx], self.y[idx]\n",
    "\n",
    "# train_dataset = CandlestickDataset(X_train, y_train)\n",
    "# test_dataset = CandlestickDataset(X_test, y_test)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # === 4. –°–û–ó–î–ê–ù–ò–ï –ù–ï–ô–†–û–°–ï–¢–ò (LSTM) ===\n",
    "# class CandleLSTM(nn.Module):\n",
    "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "#         super(CandleLSTM, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.embedding(x)\n",
    "#         x, _ = self.lstm(x)\n",
    "#         x = self.fc(x[:, -1, :])  \n",
    "#         return self.sigmoid(x)\n",
    "\n",
    "# # === 5. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –° –°–û–•–†–ê–ù–ï–ù–ò–ï–ú –õ–£–ß–®–ï–ô ===\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = CandleLSTM(\n",
    "#     vocab_size=len(unique_codes), embedding_dim=8, hidden_dim=32, output_dim=1\n",
    "#     ).to(device)\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# best_accuracy = 0  \n",
    "# model_path = \"bm_fut_lih_02.pth\"\n",
    "\n",
    "# epochs = 2000\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for X_batch, y_batch in train_loader:\n",
    "#         X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         y_pred = model(X_batch).squeeze()\n",
    "#         loss = criterion(y_pred, y_batch)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ ===\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for X_batch, y_batch in test_loader:\n",
    "#             X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "#             y_pred = model(X_batch).squeeze().round()\n",
    "#             correct += (y_pred == y_batch).sum().item()\n",
    "#             total += y_batch.size(0)\n",
    "\n",
    "#     accuracy = correct / total\n",
    "#     print(\n",
    "#         f\"Epoch {epoch+1}/{epochs}, \"\n",
    "#         f\"Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "#         f\"Test Accuracy: {accuracy:.2%}\"\n",
    "#         )\n",
    "\n",
    "#     # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ ===\n",
    "#     if accuracy > best_accuracy:\n",
    "#         best_accuracy = accuracy\n",
    "#         torch.save(model.state_dict(), model_path)\n",
    "#         print(f\"‚úÖ Model saved with accuracy: {best_accuracy:.2%}\")\n",
    "\n",
    "# # === 6. –ó–ê–ì–†–£–ó–ö–ê –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò –ò –¢–ï–°–¢ ===\n",
    "# print(\"\\nüîπ Loading best model for final evaluation...\")\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "# model.eval()\n",
    "\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for X_batch, y_batch in test_loader:\n",
    "#         X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "#         y_pred = model(X_batch).squeeze().round()\n",
    "#         correct += (y_pred == y_batch).sum().item()\n",
    "#         total += y_batch.size(0)\n",
    "\n",
    "# final_accuracy = correct / total\n",
    "# print(f\"üèÜ Final Test Accuracy: {final_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Loss: 0.6934, Test Accuracy: 50.69%, Best accuracy: 0.00%, Epoch best accuracy: 0, seed: 53\n",
      "‚úÖ Model saved with accuracy: 50.69%\n",
      "Epoch 2/2000, Loss: 0.6918, Test Accuracy: 50.50%, Best accuracy: 50.69%, Epoch best accuracy: 1, seed: 53\n",
      "Epoch 3/2000, Loss: 0.6915, Test Accuracy: 50.50%, Best accuracy: 50.69%, Epoch best accuracy: 1, seed: 53\n",
      "Epoch 4/2000, Loss: 0.6910, Test Accuracy: 50.10%, Best accuracy: 50.69%, Epoch best accuracy: 1, seed: 53\n",
      "Epoch 5/2000, Loss: 0.6906, Test Accuracy: 50.30%, Best accuracy: 50.69%, Epoch best accuracy: 1, seed: 53\n",
      "Epoch 6/2000, Loss: 0.6904, Test Accuracy: 50.30%, Best accuracy: 50.69%, Epoch best accuracy: 1, seed: 53\n",
      "Epoch 7/2000, Loss: 0.6897, Test Accuracy: 50.89%, Best accuracy: 50.69%, Epoch best accuracy: 1, seed: 53\n",
      "‚úÖ Model saved with accuracy: 50.89%\n",
      "Epoch 8/2000, Loss: 0.6892, Test Accuracy: 50.50%, Best accuracy: 50.89%, Epoch best accuracy: 7, seed: 53\n",
      "Epoch 9/2000, Loss: 0.6885, Test Accuracy: 53.86%, Best accuracy: 50.89%, Epoch best accuracy: 7, seed: 53\n",
      "‚úÖ Model saved with accuracy: 53.86%\n",
      "Epoch 10/2000, Loss: 0.6882, Test Accuracy: 52.67%, Best accuracy: 53.86%, Epoch best accuracy: 9, seed: 53\n",
      "Epoch 11/2000, Loss: 0.6872, Test Accuracy: 52.08%, Best accuracy: 53.86%, Epoch best accuracy: 9, seed: 53\n",
      "Epoch 12/2000, Loss: 0.6871, Test Accuracy: 54.26%, Best accuracy: 53.86%, Epoch best accuracy: 9, seed: 53\n",
      "‚úÖ Model saved with accuracy: 54.26%\n",
      "Epoch 13/2000, Loss: 0.6853, Test Accuracy: 54.85%, Best accuracy: 54.26%, Epoch best accuracy: 12, seed: 53\n",
      "‚úÖ Model saved with accuracy: 54.85%\n",
      "Epoch 14/2000, Loss: 0.6841, Test Accuracy: 53.66%, Best accuracy: 54.85%, Epoch best accuracy: 13, seed: 53\n",
      "Epoch 15/2000, Loss: 0.6835, Test Accuracy: 54.26%, Best accuracy: 54.85%, Epoch best accuracy: 13, seed: 53\n",
      "Epoch 16/2000, Loss: 0.6801, Test Accuracy: 54.26%, Best accuracy: 54.85%, Epoch best accuracy: 13, seed: 53\n",
      "Epoch 17/2000, Loss: 0.6785, Test Accuracy: 52.67%, Best accuracy: 54.85%, Epoch best accuracy: 13, seed: 53\n",
      "Epoch 18/2000, Loss: 0.6772, Test Accuracy: 52.08%, Best accuracy: 54.85%, Epoch best accuracy: 13, seed: 53\n",
      "Epoch 19/2000, Loss: 0.6747, Test Accuracy: 54.46%, Best accuracy: 54.85%, Epoch best accuracy: 13, seed: 53\n",
      "Epoch 20/2000, Loss: 0.6726, Test Accuracy: 53.07%, Best accuracy: 54.85%, Epoch best accuracy: 13, seed: 53\n",
      "Epoch 21/2000, Loss: 0.6686, Test Accuracy: 54.85%, Best accuracy: 54.85%, Epoch best accuracy: 13, seed: 53\n",
      "Epoch 22/2000, Loss: 0.6659, Test Accuracy: 57.23%, Best accuracy: 54.85%, Epoch best accuracy: 13, seed: 53\n",
      "‚úÖ Model saved with accuracy: 57.23%\n",
      "Epoch 23/2000, Loss: 0.6634, Test Accuracy: 55.45%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 24/2000, Loss: 0.6594, Test Accuracy: 53.66%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 25/2000, Loss: 0.6570, Test Accuracy: 54.46%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 26/2000, Loss: 0.6521, Test Accuracy: 53.27%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 27/2000, Loss: 0.6472, Test Accuracy: 51.88%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 28/2000, Loss: 0.6465, Test Accuracy: 50.69%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 29/2000, Loss: 0.6414, Test Accuracy: 51.09%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 30/2000, Loss: 0.6381, Test Accuracy: 50.89%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 31/2000, Loss: 0.6294, Test Accuracy: 50.10%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 32/2000, Loss: 0.6302, Test Accuracy: 52.87%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 33/2000, Loss: 0.6226, Test Accuracy: 50.50%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 34/2000, Loss: 0.6182, Test Accuracy: 49.11%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 35/2000, Loss: 0.6168, Test Accuracy: 51.09%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 36/2000, Loss: 0.6107, Test Accuracy: 51.09%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 37/2000, Loss: 0.6059, Test Accuracy: 50.30%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 38/2000, Loss: 0.6021, Test Accuracy: 50.89%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 39/2000, Loss: 0.6000, Test Accuracy: 51.49%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 40/2000, Loss: 0.5915, Test Accuracy: 50.89%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 41/2000, Loss: 0.5866, Test Accuracy: 50.89%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 42/2000, Loss: 0.5768, Test Accuracy: 50.89%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 43/2000, Loss: 0.5768, Test Accuracy: 50.89%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 44/2000, Loss: 0.5722, Test Accuracy: 51.09%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 45/2000, Loss: 0.5646, Test Accuracy: 49.90%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 46/2000, Loss: 0.5613, Test Accuracy: 50.89%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 47/2000, Loss: 0.5534, Test Accuracy: 50.69%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 48/2000, Loss: 0.5451, Test Accuracy: 50.50%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 49/2000, Loss: 0.5413, Test Accuracy: 48.91%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 50/2000, Loss: 0.5374, Test Accuracy: 51.68%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 51/2000, Loss: 0.5340, Test Accuracy: 50.69%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 52/2000, Loss: 0.5344, Test Accuracy: 50.10%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 53/2000, Loss: 0.5232, Test Accuracy: 50.10%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 54/2000, Loss: 0.5183, Test Accuracy: 50.30%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 55/2000, Loss: 0.5131, Test Accuracy: 50.69%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 56/2000, Loss: 0.5255, Test Accuracy: 51.29%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 57/2000, Loss: 0.5080, Test Accuracy: 50.10%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 58/2000, Loss: 0.5012, Test Accuracy: 51.68%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 59/2000, Loss: 0.4939, Test Accuracy: 50.69%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 60/2000, Loss: 0.4874, Test Accuracy: 48.91%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 61/2000, Loss: 0.4806, Test Accuracy: 51.29%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 62/2000, Loss: 0.4790, Test Accuracy: 50.30%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 63/2000, Loss: 0.4776, Test Accuracy: 51.49%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 64/2000, Loss: 0.4694, Test Accuracy: 51.49%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 65/2000, Loss: 0.4588, Test Accuracy: 52.08%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 66/2000, Loss: 0.4678, Test Accuracy: 50.69%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 67/2000, Loss: 0.4703, Test Accuracy: 49.50%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 68/2000, Loss: 0.4488, Test Accuracy: 52.08%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 69/2000, Loss: 0.4450, Test Accuracy: 51.88%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 70/2000, Loss: 0.4336, Test Accuracy: 52.48%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 71/2000, Loss: 0.4298, Test Accuracy: 53.86%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 72/2000, Loss: 0.4252, Test Accuracy: 53.66%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 73/2000, Loss: 0.4289, Test Accuracy: 52.28%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 74/2000, Loss: 0.4116, Test Accuracy: 52.87%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 75/2000, Loss: 0.4128, Test Accuracy: 53.86%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 76/2000, Loss: 0.4060, Test Accuracy: 51.29%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 77/2000, Loss: 0.4066, Test Accuracy: 52.67%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 78/2000, Loss: 0.4126, Test Accuracy: 51.09%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 79/2000, Loss: 0.3925, Test Accuracy: 53.47%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 80/2000, Loss: 0.3873, Test Accuracy: 53.66%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 81/2000, Loss: 0.3797, Test Accuracy: 53.86%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 82/2000, Loss: 0.3684, Test Accuracy: 53.86%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 83/2000, Loss: 0.3597, Test Accuracy: 53.86%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 84/2000, Loss: 0.3529, Test Accuracy: 53.66%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 85/2000, Loss: 0.3564, Test Accuracy: 52.48%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 86/2000, Loss: 0.3429, Test Accuracy: 52.87%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 87/2000, Loss: 0.3357, Test Accuracy: 52.67%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 88/2000, Loss: 0.3508, Test Accuracy: 54.85%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 89/2000, Loss: 0.3309, Test Accuracy: 52.28%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 90/2000, Loss: 0.3669, Test Accuracy: 54.46%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 91/2000, Loss: 0.3443, Test Accuracy: 55.84%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 92/2000, Loss: 0.3123, Test Accuracy: 54.26%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 93/2000, Loss: 0.3064, Test Accuracy: 55.05%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 94/2000, Loss: 0.3042, Test Accuracy: 54.06%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 95/2000, Loss: 0.2912, Test Accuracy: 55.45%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 96/2000, Loss: 0.2972, Test Accuracy: 55.25%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 97/2000, Loss: 0.2830, Test Accuracy: 54.46%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 98/2000, Loss: 0.2951, Test Accuracy: 53.86%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 99/2000, Loss: 0.3212, Test Accuracy: 52.87%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 100/2000, Loss: 0.2911, Test Accuracy: 55.05%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 101/2000, Loss: 0.2756, Test Accuracy: 55.45%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 102/2000, Loss: 0.2710, Test Accuracy: 54.85%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 103/2000, Loss: 0.2535, Test Accuracy: 54.85%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 104/2000, Loss: 0.2494, Test Accuracy: 55.45%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 105/2000, Loss: 0.2457, Test Accuracy: 54.85%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 106/2000, Loss: 0.2372, Test Accuracy: 54.85%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 107/2000, Loss: 0.2450, Test Accuracy: 54.85%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 108/2000, Loss: 0.2493, Test Accuracy: 53.07%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 109/2000, Loss: 0.2418, Test Accuracy: 53.66%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 110/2000, Loss: 0.2633, Test Accuracy: 55.05%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 111/2000, Loss: 0.2811, Test Accuracy: 55.64%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 112/2000, Loss: 0.2507, Test Accuracy: 55.64%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 113/2000, Loss: 0.2338, Test Accuracy: 55.45%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 114/2000, Loss: 0.2199, Test Accuracy: 54.65%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 115/2000, Loss: 0.2063, Test Accuracy: 53.86%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 116/2000, Loss: 0.2509, Test Accuracy: 54.85%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 117/2000, Loss: 0.2316, Test Accuracy: 53.86%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 118/2000, Loss: 0.2273, Test Accuracy: 54.65%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 119/2000, Loss: 0.2064, Test Accuracy: 54.26%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 120/2000, Loss: 0.2086, Test Accuracy: 53.66%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 121/2000, Loss: 0.2383, Test Accuracy: 54.85%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 122/2000, Loss: 0.1968, Test Accuracy: 55.84%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 123/2000, Loss: 0.1857, Test Accuracy: 56.04%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 124/2000, Loss: 0.1740, Test Accuracy: 54.85%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 125/2000, Loss: 0.1679, Test Accuracy: 54.65%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 126/2000, Loss: 0.1651, Test Accuracy: 54.65%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 127/2000, Loss: 0.1609, Test Accuracy: 53.47%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 128/2000, Loss: 0.1670, Test Accuracy: 54.46%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 129/2000, Loss: 0.1707, Test Accuracy: 54.65%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 130/2000, Loss: 0.1687, Test Accuracy: 54.46%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 131/2000, Loss: 0.1604, Test Accuracy: 54.06%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 132/2000, Loss: 0.2037, Test Accuracy: 52.87%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 133/2000, Loss: 0.2089, Test Accuracy: 53.86%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 134/2000, Loss: 0.1973, Test Accuracy: 55.25%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 135/2000, Loss: 0.1978, Test Accuracy: 55.05%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 136/2000, Loss: 0.1989, Test Accuracy: 53.47%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 137/2000, Loss: 0.1816, Test Accuracy: 55.45%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 138/2000, Loss: 0.1547, Test Accuracy: 55.25%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 139/2000, Loss: 0.1527, Test Accuracy: 55.25%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 140/2000, Loss: 0.1400, Test Accuracy: 55.84%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 141/2000, Loss: 0.1251, Test Accuracy: 56.63%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 142/2000, Loss: 0.1203, Test Accuracy: 56.04%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 143/2000, Loss: 0.1154, Test Accuracy: 55.84%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 144/2000, Loss: 0.1122, Test Accuracy: 56.44%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 145/2000, Loss: 0.1116, Test Accuracy: 57.03%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 146/2000, Loss: 0.1135, Test Accuracy: 55.64%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 147/2000, Loss: 0.1952, Test Accuracy: 55.25%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 148/2000, Loss: 0.3429, Test Accuracy: 53.07%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 149/2000, Loss: 0.2310, Test Accuracy: 55.84%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "Epoch 150/2000, Loss: 0.1755, Test Accuracy: 58.02%, Best accuracy: 57.23%, Epoch best accuracy: 22, seed: 53\n",
      "‚úÖ Model saved with accuracy: 58.02%\n",
      "Epoch 151/2000, Loss: 0.1711, Test Accuracy: 56.83%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 152/2000, Loss: 0.1628, Test Accuracy: 55.45%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 153/2000, Loss: 0.1239, Test Accuracy: 56.83%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 154/2000, Loss: 0.1077, Test Accuracy: 57.03%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 155/2000, Loss: 0.0982, Test Accuracy: 56.63%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 156/2000, Loss: 0.0941, Test Accuracy: 57.23%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 157/2000, Loss: 0.0906, Test Accuracy: 56.83%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 158/2000, Loss: 0.0883, Test Accuracy: 57.03%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 159/2000, Loss: 0.0847, Test Accuracy: 56.83%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 160/2000, Loss: 0.1061, Test Accuracy: 56.24%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 161/2000, Loss: 0.0984, Test Accuracy: 57.23%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 162/2000, Loss: 0.1300, Test Accuracy: 55.25%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 163/2000, Loss: 0.2132, Test Accuracy: 54.46%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 164/2000, Loss: 0.1467, Test Accuracy: 53.07%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 165/2000, Loss: 0.1570, Test Accuracy: 55.25%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 166/2000, Loss: 0.1086, Test Accuracy: 55.45%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 167/2000, Loss: 0.0864, Test Accuracy: 56.63%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 168/2000, Loss: 0.0808, Test Accuracy: 56.63%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 169/2000, Loss: 0.0767, Test Accuracy: 57.03%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 170/2000, Loss: 0.0733, Test Accuracy: 57.03%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 171/2000, Loss: 0.0716, Test Accuracy: 56.83%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 172/2000, Loss: 0.0685, Test Accuracy: 57.23%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 173/2000, Loss: 0.0662, Test Accuracy: 56.63%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 174/2000, Loss: 0.0647, Test Accuracy: 57.23%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "Epoch 175/2000, Loss: 0.0621, Test Accuracy: 58.22%, Best accuracy: 58.02%, Epoch best accuracy: 150, seed: 53\n",
      "‚úÖ Model saved with accuracy: 58.22%\n",
      "Epoch 176/2000, Loss: 0.0598, Test Accuracy: 57.03%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 177/2000, Loss: 0.0575, Test Accuracy: 57.03%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 178/2000, Loss: 0.0565, Test Accuracy: 57.23%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 179/2000, Loss: 0.0553, Test Accuracy: 56.63%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 180/2000, Loss: 0.0538, Test Accuracy: 55.45%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 181/2000, Loss: 0.0710, Test Accuracy: 55.45%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 182/2000, Loss: 0.1605, Test Accuracy: 55.25%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 183/2000, Loss: 0.3431, Test Accuracy: 56.83%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 184/2000, Loss: 0.2456, Test Accuracy: 57.62%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 185/2000, Loss: 0.1915, Test Accuracy: 54.26%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 186/2000, Loss: 0.1254, Test Accuracy: 56.24%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 187/2000, Loss: 0.1720, Test Accuracy: 53.86%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 188/2000, Loss: 0.1370, Test Accuracy: 56.83%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 189/2000, Loss: 0.0853, Test Accuracy: 56.24%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 190/2000, Loss: 0.0736, Test Accuracy: 56.24%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 191/2000, Loss: 0.0689, Test Accuracy: 56.04%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 192/2000, Loss: 0.0594, Test Accuracy: 56.04%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 193/2000, Loss: 0.0547, Test Accuracy: 56.04%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 194/2000, Loss: 0.0543, Test Accuracy: 57.03%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 195/2000, Loss: 0.0536, Test Accuracy: 56.83%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 196/2000, Loss: 0.0488, Test Accuracy: 55.45%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 197/2000, Loss: 0.0491, Test Accuracy: 57.82%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 198/2000, Loss: 0.0457, Test Accuracy: 57.62%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 199/2000, Loss: 0.0418, Test Accuracy: 57.43%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 200/2000, Loss: 0.0404, Test Accuracy: 57.03%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 201/2000, Loss: 0.0380, Test Accuracy: 57.23%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 202/2000, Loss: 0.0369, Test Accuracy: 57.03%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 203/2000, Loss: 0.0356, Test Accuracy: 56.83%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 204/2000, Loss: 0.0343, Test Accuracy: 57.62%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 205/2000, Loss: 0.0340, Test Accuracy: 56.63%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 206/2000, Loss: 0.0334, Test Accuracy: 57.03%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 207/2000, Loss: 0.0325, Test Accuracy: 58.22%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 208/2000, Loss: 0.0309, Test Accuracy: 57.43%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 209/2000, Loss: 0.0309, Test Accuracy: 56.44%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 210/2000, Loss: 0.0290, Test Accuracy: 57.82%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 211/2000, Loss: 0.0286, Test Accuracy: 57.43%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 212/2000, Loss: 0.0274, Test Accuracy: 57.62%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 213/2000, Loss: 0.0261, Test Accuracy: 56.83%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 214/2000, Loss: 0.0250, Test Accuracy: 57.43%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 215/2000, Loss: 0.0244, Test Accuracy: 57.82%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 216/2000, Loss: 0.0436, Test Accuracy: 55.84%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 217/2000, Loss: 0.5394, Test Accuracy: 57.62%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 218/2000, Loss: 0.5578, Test Accuracy: 55.25%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 219/2000, Loss: 0.4003, Test Accuracy: 55.84%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 220/2000, Loss: 0.2357, Test Accuracy: 58.22%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 221/2000, Loss: 0.1430, Test Accuracy: 56.83%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 222/2000, Loss: 0.1034, Test Accuracy: 56.83%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 223/2000, Loss: 0.0878, Test Accuracy: 56.04%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 224/2000, Loss: 0.0907, Test Accuracy: 56.24%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 225/2000, Loss: 0.0664, Test Accuracy: 56.44%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 226/2000, Loss: 0.0617, Test Accuracy: 56.04%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 227/2000, Loss: 0.0510, Test Accuracy: 56.24%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 228/2000, Loss: 0.0479, Test Accuracy: 57.03%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 229/2000, Loss: 0.0440, Test Accuracy: 57.23%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 230/2000, Loss: 0.0485, Test Accuracy: 56.24%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 231/2000, Loss: 0.0893, Test Accuracy: 58.02%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 232/2000, Loss: 0.0774, Test Accuracy: 58.22%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 233/2000, Loss: 0.0528, Test Accuracy: 57.43%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 234/2000, Loss: 0.0474, Test Accuracy: 55.84%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 235/2000, Loss: 0.0424, Test Accuracy: 57.23%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 236/2000, Loss: 0.0514, Test Accuracy: 56.44%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 237/2000, Loss: 0.0381, Test Accuracy: 56.24%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 238/2000, Loss: 0.0326, Test Accuracy: 56.63%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 239/2000, Loss: 0.0294, Test Accuracy: 56.83%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 240/2000, Loss: 0.0279, Test Accuracy: 58.02%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 241/2000, Loss: 0.0288, Test Accuracy: 57.23%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 242/2000, Loss: 0.0254, Test Accuracy: 57.62%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 243/2000, Loss: 0.0242, Test Accuracy: 57.82%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 244/2000, Loss: 0.0232, Test Accuracy: 57.62%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 245/2000, Loss: 0.0224, Test Accuracy: 58.22%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 246/2000, Loss: 0.0216, Test Accuracy: 58.22%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 247/2000, Loss: 0.0205, Test Accuracy: 57.23%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 248/2000, Loss: 0.0199, Test Accuracy: 57.82%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 249/2000, Loss: 0.0190, Test Accuracy: 57.62%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 250/2000, Loss: 0.0185, Test Accuracy: 58.02%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 251/2000, Loss: 0.0179, Test Accuracy: 57.82%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 252/2000, Loss: 0.0174, Test Accuracy: 57.62%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 253/2000, Loss: 0.0168, Test Accuracy: 58.22%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "Epoch 254/2000, Loss: 0.0163, Test Accuracy: 58.42%, Best accuracy: 58.22%, Epoch best accuracy: 175, seed: 53\n",
      "‚úÖ Model saved with accuracy: 58.42%\n",
      "Epoch 255/2000, Loss: 0.0156, Test Accuracy: 57.82%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 256/2000, Loss: 0.0152, Test Accuracy: 57.82%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 257/2000, Loss: 0.0146, Test Accuracy: 57.62%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 258/2000, Loss: 0.0138, Test Accuracy: 57.43%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 259/2000, Loss: 0.0135, Test Accuracy: 57.62%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 260/2000, Loss: 0.0131, Test Accuracy: 58.02%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 261/2000, Loss: 0.0128, Test Accuracy: 58.42%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 262/2000, Loss: 0.0123, Test Accuracy: 57.03%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 263/2000, Loss: 0.2576, Test Accuracy: 54.46%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 264/2000, Loss: 0.5063, Test Accuracy: 54.46%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 265/2000, Loss: 0.2703, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 266/2000, Loss: 0.1626, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 267/2000, Loss: 0.0998, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 268/2000, Loss: 0.0734, Test Accuracy: 54.46%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 269/2000, Loss: 0.0546, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 270/2000, Loss: 0.0586, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 271/2000, Loss: 0.0412, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 272/2000, Loss: 0.0310, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 273/2000, Loss: 0.0251, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 274/2000, Loss: 0.0223, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 275/2000, Loss: 0.0201, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 276/2000, Loss: 0.0189, Test Accuracy: 56.44%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 277/2000, Loss: 0.0177, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 278/2000, Loss: 0.0169, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 279/2000, Loss: 0.0162, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 280/2000, Loss: 0.0154, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 281/2000, Loss: 0.0148, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 282/2000, Loss: 0.0143, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 283/2000, Loss: 0.0138, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 284/2000, Loss: 0.0132, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 285/2000, Loss: 0.0127, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 286/2000, Loss: 0.0124, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 287/2000, Loss: 0.0119, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 288/2000, Loss: 0.0115, Test Accuracy: 57.03%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 289/2000, Loss: 0.0112, Test Accuracy: 55.45%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 290/2000, Loss: 0.0108, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 291/2000, Loss: 0.0104, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 292/2000, Loss: 0.0101, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 293/2000, Loss: 0.0098, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 294/2000, Loss: 0.0095, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 295/2000, Loss: 0.0092, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 296/2000, Loss: 0.0089, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 297/2000, Loss: 0.0086, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 298/2000, Loss: 0.0084, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 299/2000, Loss: 0.0081, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 300/2000, Loss: 0.0079, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 301/2000, Loss: 0.0076, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 302/2000, Loss: 0.0074, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 303/2000, Loss: 0.0071, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 304/2000, Loss: 0.0069, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 305/2000, Loss: 0.0067, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 306/2000, Loss: 0.0065, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 307/2000, Loss: 0.0063, Test Accuracy: 55.45%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 308/2000, Loss: 0.0061, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 309/2000, Loss: 0.0059, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 310/2000, Loss: 0.0058, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 311/2000, Loss: 0.0055, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 312/2000, Loss: 0.0054, Test Accuracy: 55.45%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 313/2000, Loss: 0.0052, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 314/2000, Loss: 0.0051, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 315/2000, Loss: 0.0049, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 316/2000, Loss: 0.0048, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 317/2000, Loss: 0.0046, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 318/2000, Loss: 0.0045, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 319/2000, Loss: 0.0043, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 320/2000, Loss: 0.0042, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 321/2000, Loss: 0.0041, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 322/2000, Loss: 0.0040, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 323/2000, Loss: 0.0044, Test Accuracy: 53.86%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 324/2000, Loss: 0.8652, Test Accuracy: 57.82%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 325/2000, Loss: 0.7321, Test Accuracy: 53.27%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 326/2000, Loss: 0.4218, Test Accuracy: 56.63%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 327/2000, Loss: 0.2763, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 328/2000, Loss: 0.1700, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 329/2000, Loss: 0.1234, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 330/2000, Loss: 0.0782, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 331/2000, Loss: 0.0696, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 332/2000, Loss: 0.0498, Test Accuracy: 56.83%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 333/2000, Loss: 0.0415, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 334/2000, Loss: 0.0336, Test Accuracy: 56.63%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 335/2000, Loss: 0.0314, Test Accuracy: 57.62%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 336/2000, Loss: 0.0267, Test Accuracy: 57.23%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 337/2000, Loss: 0.0252, Test Accuracy: 58.02%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 338/2000, Loss: 0.0243, Test Accuracy: 57.43%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 339/2000, Loss: 0.0217, Test Accuracy: 57.62%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 340/2000, Loss: 0.0203, Test Accuracy: 57.82%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 341/2000, Loss: 0.0194, Test Accuracy: 57.62%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 342/2000, Loss: 0.0182, Test Accuracy: 57.62%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 343/2000, Loss: 0.0172, Test Accuracy: 57.23%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 344/2000, Loss: 0.0164, Test Accuracy: 56.63%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 345/2000, Loss: 0.0154, Test Accuracy: 56.83%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 346/2000, Loss: 0.0147, Test Accuracy: 57.23%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 347/2000, Loss: 0.0142, Test Accuracy: 56.44%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 348/2000, Loss: 0.0135, Test Accuracy: 56.44%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 349/2000, Loss: 0.0130, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 350/2000, Loss: 0.0125, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 351/2000, Loss: 0.0120, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 352/2000, Loss: 0.0116, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 353/2000, Loss: 0.0111, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 354/2000, Loss: 0.0106, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 355/2000, Loss: 0.0103, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 356/2000, Loss: 0.0098, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 357/2000, Loss: 0.0094, Test Accuracy: 56.83%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 358/2000, Loss: 0.0092, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 359/2000, Loss: 0.0088, Test Accuracy: 55.45%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 360/2000, Loss: 0.0085, Test Accuracy: 56.63%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 361/2000, Loss: 0.0082, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 362/2000, Loss: 0.0078, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 363/2000, Loss: 0.0075, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 364/2000, Loss: 0.0072, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 365/2000, Loss: 0.0071, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 366/2000, Loss: 0.0067, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 367/2000, Loss: 0.0065, Test Accuracy: 56.24%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 368/2000, Loss: 0.0062, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 369/2000, Loss: 0.0060, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 370/2000, Loss: 0.0057, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 371/2000, Loss: 0.0055, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 372/2000, Loss: 0.0053, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 373/2000, Loss: 0.0051, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 374/2000, Loss: 0.0049, Test Accuracy: 56.44%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 375/2000, Loss: 0.0048, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 376/2000, Loss: 0.3426, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 377/2000, Loss: 0.4564, Test Accuracy: 55.64%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 378/2000, Loss: 0.3620, Test Accuracy: 56.63%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 379/2000, Loss: 0.2239, Test Accuracy: 57.03%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 380/2000, Loss: 0.1892, Test Accuracy: 54.26%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 381/2000, Loss: 0.0966, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 382/2000, Loss: 0.0583, Test Accuracy: 54.06%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 383/2000, Loss: 0.0560, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 384/2000, Loss: 0.0380, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 385/2000, Loss: 0.0234, Test Accuracy: 56.44%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 386/2000, Loss: 0.0189, Test Accuracy: 56.04%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 387/2000, Loss: 0.0168, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 388/2000, Loss: 0.0152, Test Accuracy: 55.45%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 389/2000, Loss: 0.0140, Test Accuracy: 55.84%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 390/2000, Loss: 0.0131, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 391/2000, Loss: 0.0122, Test Accuracy: 55.45%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 392/2000, Loss: 0.0116, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 393/2000, Loss: 0.0109, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 394/2000, Loss: 0.0103, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 395/2000, Loss: 0.0098, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 396/2000, Loss: 0.0093, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 397/2000, Loss: 0.0088, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 398/2000, Loss: 0.0084, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 399/2000, Loss: 0.0081, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 400/2000, Loss: 0.0078, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 401/2000, Loss: 0.0075, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 402/2000, Loss: 0.0072, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 403/2000, Loss: 0.0069, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 404/2000, Loss: 0.0067, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 405/2000, Loss: 0.0065, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 406/2000, Loss: 0.0063, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 407/2000, Loss: 0.0061, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 408/2000, Loss: 0.0059, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 409/2000, Loss: 0.0057, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 410/2000, Loss: 0.0055, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 411/2000, Loss: 0.0053, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 412/2000, Loss: 0.0052, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 413/2000, Loss: 0.0050, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 414/2000, Loss: 0.0049, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 415/2000, Loss: 0.0047, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 416/2000, Loss: 0.0045, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 417/2000, Loss: 0.0044, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 418/2000, Loss: 0.0043, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 419/2000, Loss: 0.0042, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 420/2000, Loss: 0.0040, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 421/2000, Loss: 0.0039, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 422/2000, Loss: 0.0038, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 423/2000, Loss: 0.0037, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 424/2000, Loss: 0.0036, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 425/2000, Loss: 0.0035, Test Accuracy: 54.46%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 426/2000, Loss: 0.0034, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 427/2000, Loss: 0.0033, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 428/2000, Loss: 0.0032, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 429/2000, Loss: 0.0031, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 430/2000, Loss: 0.0030, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 431/2000, Loss: 0.0029, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 432/2000, Loss: 0.0028, Test Accuracy: 54.46%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 433/2000, Loss: 0.0027, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 434/2000, Loss: 0.0027, Test Accuracy: 54.46%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 435/2000, Loss: 0.0026, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 436/2000, Loss: 0.0025, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 437/2000, Loss: 0.0024, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 438/2000, Loss: 0.0024, Test Accuracy: 54.46%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 439/2000, Loss: 0.0023, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 440/2000, Loss: 0.0022, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 441/2000, Loss: 0.0022, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 442/2000, Loss: 0.0021, Test Accuracy: 54.06%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 443/2000, Loss: 0.0020, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 444/2000, Loss: 0.0020, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 445/2000, Loss: 0.0019, Test Accuracy: 54.85%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 446/2000, Loss: 0.0019, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 447/2000, Loss: 0.0018, Test Accuracy: 54.65%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 448/2000, Loss: 0.0018, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 449/2000, Loss: 0.0017, Test Accuracy: 55.05%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 450/2000, Loss: 0.0017, Test Accuracy: 55.45%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 451/2000, Loss: 0.0016, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 452/2000, Loss: 0.0017, Test Accuracy: 55.45%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 453/2000, Loss: 0.1621, Test Accuracy: 55.25%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "Epoch 454/2000, Loss: 0.9395, Test Accuracy: 54.46%, Best accuracy: 58.42%, Epoch best accuracy: 254, seed: 53\n",
      "üõë Early stopping at epoch 454\n",
      "\n",
      "üîπ Loading best model for final evaluation...\n",
      "üèÜ Final Test Accuracy: 58.42%\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# === 1. –§–ò–ö–°–ê–¶–ò–Ø –°–õ–£–ß–ê–ô–ù–´–• –ß–ò–°–ï–õ –î–õ–Ø –î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–û–°–¢–ò ===\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# [53, 84], 1, 11, 15, 27, 32, 47, 53, 78, 82, 84, 91\n",
    "set_seed(53)  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π seed\n",
    "\n",
    "# === 2. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ===\n",
    "db_path = Path(r'C:\\Users\\Alkor\\gd\\data_quote_db\\RTS_futures_options_day.db')\n",
    "\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    df_fut = pd.read_sql_query(\n",
    "        \"SELECT TRADEDATE, OPEN, LOW, HIGH, CLOSE, VOLUME FROM Futures\",\n",
    "        conn\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "–°—Ç—Ä–æ–∫–∞ –Ω–∏–∂–µ.\n",
    "–§–∏–∫—Å–∞—Ü–∏—è –ø–æ—Ä—è–¥–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ). –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç.–∫. \n",
    "–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∏—á–µ–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–≤–µ—á–µ–π.\n",
    "\"\"\"\n",
    "# df_fut = df_fut.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# === 3. –§–£–ù–ö–¶–ò–Ø –ö–û–î–ò–†–û–í–ê–ù–ò–Ø –°–í–ï–ß–ï–ô (–õ–ò–•–û–í–ò–î–û–í) ===\n",
    "def encode_candle(row):\n",
    "    open_, low, high, close = row['OPEN'], row['LOW'], row['HIGH'], row['CLOSE']\n",
    "\n",
    "    direction = 1 if close > open_ else (0 if close < open_ else 2)\n",
    "    upper_shadow = high - max(open_, close)\n",
    "    lower_shadow = min(open_, close) - low\n",
    "    body = abs(close - open_)\n",
    "\n",
    "    def classify_shadow(shadow, body):\n",
    "        return 0 if shadow < 0.1 * body else (1 if shadow < 0.5 * body else 2)\n",
    "\n",
    "    return f\"{direction}{classify_shadow(upper_shadow, body)}{classify_shadow(lower_shadow, body)}\"\n",
    "\n",
    "df_fut['CANDLE_CODE'] = df_fut.apply(encode_candle, axis=1)\n",
    "\n",
    "# === 4. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ===\n",
    "unique_codes = sorted(df_fut['CANDLE_CODE'].unique())\n",
    "code_to_int = {code: i for i, code in enumerate(unique_codes)}\n",
    "df_fut['CANDLE_INT'] = df_fut['CANDLE_CODE'].map(code_to_int)\n",
    "\n",
    "window_size = 20  \n",
    "predict_offset = 1  \n",
    "\n",
    "X, y = [], []\n",
    "for i in range(len(df_fut) - window_size - predict_offset):\n",
    "    X.append(df_fut['CANDLE_INT'].iloc[i:i+window_size].values)\n",
    "    y.append(\n",
    "        1 if df_fut['CLOSE'].iloc[i+window_size+predict_offset] > \n",
    "        df_fut['CLOSE'].iloc[i+window_size] else 0\n",
    "    )\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:split], y[:split]\n",
    "X_test, y_test = X[split:], y[split:]\n",
    "\n",
    "class CandlestickDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    np.random.seed(42 + worker_id)\n",
    "    random.seed(42 + worker_id)\n",
    "\n",
    "train_dataset = CandlestickDataset(X_train, y_train)\n",
    "test_dataset = CandlestickDataset(X_test, y_test)\n",
    "# print(X_train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, worker_init_fn=seed_worker)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, worker_init_fn=seed_worker)\n",
    "\n",
    "# === 5. –°–û–ó–î–ê–ù–ò–ï –ù–ï–ô–†–û–°–ï–¢–ò (LSTM) ===\n",
    "class CandleLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(CandleLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])  \n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# === 6. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –° –°–û–•–†–ê–ù–ï–ù–ò–ï–ú –õ–£–ß–®–ï–ô ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CandleLSTM(\n",
    "    vocab_size=len(unique_codes), embedding_dim=8, hidden_dim=32, output_dim=1\n",
    ").to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_accuracy = 0  \n",
    "epoch_best_accuracy = 0\n",
    "model_path = \"bm_fut_lih_02.pth\"\n",
    "early_stop_epochs = 200  # –î–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
    "epochs_no_improve = 0\n",
    "\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch).squeeze()\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ ===\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch).squeeze().round()\n",
    "            correct += (y_pred == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs}, \"\n",
    "        f\"Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "        f\"Test Accuracy: {accuracy:.2%}, \"\n",
    "        f\"Best accuracy: {best_accuracy:.2%}, \"\n",
    "        f\"Epoch best accuracy: {epoch_best_accuracy}, \"\n",
    "        f\"seed: 53\"\n",
    "    )\n",
    "\n",
    "    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ ===\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        epochs_no_improve = 0\n",
    "        epoch_best_accuracy = epoch + 1\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"‚úÖ Model saved with accuracy: {best_accuracy:.2%}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # === –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ ===\n",
    "    if epochs_no_improve >= early_stop_epochs:\n",
    "        print(f\"üõë Early stopping at epoch {epoch + 1}\")\n",
    "        break\n",
    "\n",
    "# === 7. –ó–ê–ì–†–£–ó–ö–ê –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò –ò –¢–ï–°–¢ ===\n",
    "print(\"\\nüîπ Loading best model for final evaluation...\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred = model(X_batch).squeeze().round()\n",
    "        correct += (y_pred == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "final_accuracy = correct / total\n",
    "print(f\"üèÜ Final Test Accuracy: {final_accuracy:.2%}\")\n",
    "\n",
    "# # === 8. –°–û–•–†–ê–ù–ï–ù–ò–ï –í–ï–†–°–ò–ô –ë–ò–ë–õ–ò–û–¢–ï–ö ===\n",
    "# print(\"\\nüîπ Library versions:\")\n",
    "# print(f\"PyTorch: {torch.__version__}\")\n",
    "# print(f\"NumPy: {np.__version__}\")\n",
    "# print(f\"Pandas: {pd.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîπ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è?  \n",
    "–ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–π —Å–≤–µ—á–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: üìâ DOWN\n",
      "UP Probability: 0.01%, \n",
      "DOWN Probability: 99.99%\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model.load_state_dict(torch.load(\"bm_fut_lih_02.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–≤–µ—á–µ–π –∏–∑ df_fut\n",
    "last_sequence = torch.tensor(\n",
    "    df_fut['CANDLE_INT'].iloc[-20:].values, dtype=torch.long\n",
    "    ).unsqueeze(0).to(device)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "with torch.no_grad():\n",
    "    probability_up = model(last_sequence).item()  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞\n",
    "    probability_down = 1 - probability_up  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–∞–¥–µ–Ω–∏—è\n",
    "\n",
    "    direction = \"üìà UP\" if probability_up >= 0.5 else \"üìâ DOWN\"\n",
    "\n",
    "    print(f\"Prediction: {direction}\")\n",
    "    print(\n",
    "        f\"UP Probability: {probability_up:.2%}, \\n\"\n",
    "        f\"DOWN Probability: {probability_down:.2%}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
